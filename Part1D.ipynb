{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "import sys\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    \n",
    "    X = x-mean\n",
    "    X=X/std\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hypothesis(X,theta):\n",
    "    return np.dot(X,theta)\n",
    "\n",
    "def find_J_theta(X,Y,theta):\n",
    "    hypothesis = find_hypothesis(X,theta)\n",
    "    difference =  Y - hypothesis\n",
    "    sum_sq = np.dot(difference.transpose(),difference)\n",
    "    return sum_sq[0,0]/(2*X.shape[0])\n",
    "\n",
    "def gradient(X,Y,theta):\n",
    "    term1 = np.dot(X.transpose(),X)\n",
    "    term2 = np.dot(term1,theta)\n",
    "    term3 = np.dot(X.transpose(),Y)\n",
    "    return(term2-term3)\n",
    "\n",
    "def SGD(X,Y, learning_rate=0.001, error_threshold = 0.0000001):\n",
    "    \n",
    "    # theta shape is number of unknown parameters * 1 (2*1)\n",
    "    theta = np.zeros((X.shape[1],1)) \n",
    "    \n",
    "    list_error = []\n",
    "    list_theta = []\n",
    "    \n",
    "    list_theta.append(theta)\n",
    "    \n",
    "    # Finding the error\n",
    "    J_theta = find_J_theta(X,Y,theta)\n",
    "    list_error.append(J_theta)\n",
    "    \n",
    "    epoch = 0\n",
    "    while(True):\n",
    "        epoch+=1\n",
    "        theta = theta - learning_rate * gradient(X, Y, theta)\n",
    "        J_theta_new = find_J_theta(X,Y,theta)\n",
    "            \n",
    "        list_error.append(J_theta_new)\n",
    "        list_theta.append(theta)\n",
    "        \n",
    "        if(abs(J_theta_new-J_theta)<error_threshold or epoch>100):\n",
    "            return theta,list_error, list_theta,epoch\n",
    "        J_theta = J_theta_new.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = genfromtxt('data/q1/linearX.csv', delimiter=',')\n",
    "Y = genfromtxt('data/q1/linearY.csv',delimiter=',')\n",
    "\n",
    "X_normal = normalize(X)\n",
    "Y_normal = Y.copy()\n",
    "\n",
    "if(debug):\n",
    "    print(X)\n",
    "    print(X_normal)\n",
    "    \n",
    "    print(Y)\n",
    "    print(Y_normal)\n",
    "\n",
    "X_normal=X_normal.reshape(-1,1)\n",
    "Y_normal=Y_normal.reshape(-1,1)\n",
    "\n",
    "\n",
    "# Adding the intercept\n",
    "X_normal=np.hstack((X_normal,np.ones((X_normal.shape[0],1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001]\n",
    "\n",
    "print(\"Stoping criteria : abs cost difference < 0.0000001 or epoch>100\")\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    theta, lst_error,lst_theta,epoch = SGD(X_normal, Y_normal,learning_rate = learning_rate )\n",
    "    print(\"Learning rate :\",learning_rate)\n",
    "    print(\"Number of epochs :\",epoch)\n",
    "    print(\"Final Theta :\\n\",theta)\n",
    "    \n",
    "    # evenly spaced sequence in a specified interval\n",
    "    X_axis = np.linspace(-1,1,100)\n",
    "    Y_axis = np.linspace(-1,1,100)\n",
    "\n",
    "    X1, Y1 = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "    Z1 = np.asmatrix(np.zeros((100,100),dtype=float))\n",
    "\n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            Z1[i,j]=find_J_theta(X_normal, Y_normal,[[X1[i][j]],[Y1[i][j]]])\n",
    "\n",
    "    Z1 = np.array(Z1)\n",
    "\n",
    "    th0 = np.zeros((len(lst_theta),1),dtype=float)\n",
    "\n",
    "    for i in range(len(lst_theta)):\n",
    "        th0[i,0]=lst_theta[i][0]\n",
    "\n",
    "\n",
    "    th1 = np.zeros((len(lst_theta),1),dtype=float)\n",
    "    for i in range(len(lst_theta)):\n",
    "        th1[i,0]=lst_theta[i][1]\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "    plt.contour(Y1, X1, Z1, 50)\n",
    "\n",
    "    plt.xlabel('theta0')\n",
    "    plt.ylabel('theta1')\n",
    "    \n",
    "    title_p = \"2D contours showing the error function at each iteration (learning rate :\"+str(learning_rate)+\")\"\n",
    "    \n",
    "    plt.title(title_p)\n",
    "\n",
    "\n",
    "    plt.ion()  \n",
    "    for i in range(th0.shape[0]):\n",
    "        plt.scatter(th1[i], th0[i], color=\"r\")\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "        plt.pause(0.2)\n",
    "    plt.ioff()\n",
    "\n",
    "    plt.savefig('output/Ques1(d)_'+str(learning_rate)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
