{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "import sys\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "debug = True\n",
    "from numpy import genfromtxt\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000000\n",
    "\n",
    "# Normal Distribution (Data)\n",
    "X1 = np.random.normal(3, 4, sample_size)\n",
    "X2 = np.random.normal(-1, 4, sample_size)\n",
    "\n",
    "X = []\n",
    "# Adding the intercept\n",
    "for i in range(sample_size):\n",
    "    X.append([1.0,X1[i],X2[i]])\n",
    "\n",
    "X= np.array(X)\n",
    "\n",
    "# noise\n",
    "e = np.random.normal(0,math.sqrt(2))\n",
    "\n",
    "# Initializing theta\n",
    "theta = np.array([3,1,2]).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(X,Y,batch_size):\n",
    "\n",
    "    data_join = np.hstack((X,Y))\n",
    "    \n",
    "    # Shuffle the data\n",
    "    np.random.shuffle(data_join)\n",
    "    \n",
    "    #print(data_join)\n",
    "    \n",
    "    # Find the number of batch possible\n",
    "    batch_n = data_join.shape[0]//batch_size\n",
    "    \n",
    "    # Store each batch\n",
    "    batch = []\n",
    "    \n",
    "    i=0\n",
    "    for i in range(batch_n):\n",
    "        tmp = data_join[i * batch_size : (i+1) * batch_size, :]\n",
    "        X_new = tmp[:,[0,1,2]]\n",
    "        Y_new = tmp[:,[3]]\n",
    "        batch.append((X_new,Y_new))\n",
    "        \n",
    "    # If data_join is not proper multiple of batch_size then make a batch of the remaining data\n",
    "    \n",
    "    if(data_join.shape[0]%batch_size!=0):\n",
    "        tmp = data_join[(i+1) * batch_size : , :]\n",
    "        X_new = tmp[:,[0,1,2]]\n",
    "        Y_new = tmp[:,[3]]\n",
    "        batch.append((X_new,Y_new))\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hypothesis(X,theta):\n",
    "    return np.dot(X,theta)\n",
    "\n",
    "def find_J_theta(X,Y,theta):\n",
    "    hypothesis = find_hypothesis(X,theta)\n",
    "    difference =  Y - hypothesis\n",
    "    sum_sq = np.dot(difference.transpose(),difference)\n",
    "    return sum_sq[0,0]/(2*X.shape[0])\n",
    "\n",
    "def gradient(X,Y,theta):\n",
    "    term1 = np.dot(X.T,X)\n",
    "    term2 = np.dot(term1,theta)\n",
    "    term3 = np.dot(X.transpose(),Y)\n",
    "    return(term2-term3)\n",
    "    \n",
    "\n",
    "def batch_SGD(X,Y, learning_rate=0.000001, batch_size=10000, error_threshold = 1e-4):\n",
    "    \n",
    "    # theta shape is number of unknown parameters * 1 (2*1)\n",
    "    print(X.shape)\n",
    "    theta = np.zeros((X.shape[1],1)) \n",
    "    \n",
    "    list_error = []\n",
    "    list_theta = []\n",
    "    \n",
    "    list_theta.append(theta)\n",
    "    \n",
    "    # Finding the error\n",
    "    J_theta = find_J_theta(X,Y,theta)\n",
    "    list_error.append(J_theta)\n",
    "    \n",
    "    epoch = 0\n",
    "    while(True):\n",
    "        epoch+=1\n",
    "        batches =  make_batch(X,Y,batch_size)\n",
    "        \n",
    "        for X_batch, Y_batch  in batches:\n",
    "            theta = theta - learning_rate * gradient(X_batch, Y_batch, theta)  \n",
    "        \n",
    "        J_theta_new = find_J_theta(X,Y,theta)\n",
    "            \n",
    "        list_error.append(J_theta_new)\n",
    "        list_theta.append(theta)\n",
    "        \n",
    "        if(abs(J_theta_new-J_theta)<error_threshold or epoch>20):\n",
    "            return theta,list_error, list_theta,epoch\n",
    "        J_theta = J_theta_new.copy()   \n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we know the expected theta thus we can find the Y = theta * X\n",
    "Y = np.matmul(X,theta)\n",
    "Y = Y.reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch_size : 1 , learning_rate : 0.001 , threshold : 1e-05\n",
      "(1000000, 3)\n",
      "Number of epochs : 2\n",
      "Final Theta :\n",
      " [[3.]\n",
      " [1.]\n",
      " [2.]]\n",
      "For batch_size : 100 , learning_rate : 0.0005 , threshold : 1e-05\n",
      "(1000000, 3)\n",
      "Number of epochs : 2\n",
      "Final Theta :\n",
      " [[3.]\n",
      " [1.]\n",
      " [2.]]\n",
      "For batch_size : 10000 , learning_rate : 1e-06 , threshold : 0.0001\n",
      "(1000000, 3)\n",
      "Number of epochs : 10\n",
      "Final Theta :\n",
      " [[2.99329815]\n",
      " [1.00079373]\n",
      " [1.99972918]]\n",
      "For batch_size : 1000000 , learning_rate : 1e-06 , threshold : 0.01\n",
      "(1000000, 3)\n",
      "Number of epochs : 21\n",
      "Final Theta :\n",
      " [[ 2.71998822e+28]\n",
      " [ 2.07154925e+29]\n",
      " [-6.91148541e+28]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = [1, 100, 10000, 1000000]\n",
    "learning_rate = [0.001, 0.0005, 0.000001, 0.000001]\n",
    "threshold = [1e-5, 1e-5, 1e-4, 1e-2]\n",
    "#batch_size = [ 100]\n",
    "#learning_rate = [ 0.0005]\n",
    "#threshold = [ 1e-5]\n",
    "\n",
    "\n",
    "for i in range(len(batch_size)):\n",
    "    print(\"For batch_size :\",batch_size[i],\", learning_rate :\",learning_rate[i],\", threshold :\",threshold[i])\n",
    "    \n",
    "    theta, lst_error,lst_theta,epoch = batch_SGD(X, Y,learning_rate[i],batch_size[i],threshold[i])\n",
    "    print(\"Number of epochs :\",epoch)\n",
    "    print(\"Final Theta :\\n\",theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for the original theta : 0.9829469214999997\n",
      "For batch_size : 1 , learning_rate : 0.001 , threshold : 1e-05\n",
      "(1000000, 3)\n",
      "Number of epochs : 2\n",
      "Final Theta :\n",
      " [[3.]\n",
      " [1.]\n",
      " [2.]]\n",
      "Error : 0.9829469215000005\n",
      "For batch_size : 100 , learning_rate : 0.0005 , threshold : 1e-05\n",
      "(1000000, 3)\n",
      "Number of epochs : 2\n",
      "Final Theta :\n",
      " [[3.]\n",
      " [1.]\n",
      " [2.]]\n",
      "Error : 0.9829469214999997\n",
      "For batch_size : 10000 , learning_rate : 1e-06 , threshold : 0.0001\n",
      "(1000000, 3)\n",
      "Number of epochs : 10\n",
      "Final Theta :\n",
      " [[2.99329921]\n",
      " [1.00079328]\n",
      " [1.99973549]]\n",
      "Error : 0.9830253904102865\n",
      "For batch_size : 1000000 , learning_rate : 1e-06 , threshold : 0.01\n",
      "(1000000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "X_tmp = genfromtxt('data/q2/q2test.csv', delimiter=',')\n",
    "\n",
    "# First row of this data is nan remove that row\n",
    "X_tmp = X_tmp[1:]\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for i in range(len(X_tmp)):\n",
    "    X_test.append([1.,X_tmp[i][0],X_tmp[i][1]])\n",
    "    Y_test.append([X_tmp[i][2]])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# error for the given theta\n",
    "# Initializing theta\n",
    "theta1 = np.array([3,1,2]).reshape((-1,1))\n",
    "\n",
    "print(\"Error for the original theta :\",find_J_theta(X_test,Y_test,theta1))\n",
    "\n",
    "for i in range(len(batch_size)):\n",
    "    print(\"For batch_size :\",batch_size[i],\", learning_rate :\",learning_rate[i],\", threshold :\",threshold[i])\n",
    "    \n",
    "    theta, lst_error,lst_theta,epoch = batch_SGD(X, Y,learning_rate[i],batch_size[i],threshold[i])\n",
    "    print(\"Number of epochs :\",epoch)\n",
    "    print(\"Final Theta :\\n\",theta)\n",
    "    print(\"Error :\",find_J_theta(X_test,Y_test,theta))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### plot\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    # Data for three-dimensional scattered points\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    zdata = []\n",
    "    for l in lst_theta:\n",
    "        xdata.append(l[0])\n",
    "        ydata.append(l[1])\n",
    "        zdata.append(l[2])\n",
    "    ax.scatter3D(xdata, ydata, zdata, c=zdata, cmap='Greens');\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D -- above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
